{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Identify !, %, and %% used in cell in Google Colab."
      ],
      "metadata": {
        "id": "CvybPNYbzy3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "! → Shell Command\n",
        "\n",
        "Used to run terminal commands inside a notebook.\n"
      ],
      "metadata": {
        "id": "IixtqN2Zz4fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYgXyiAxz4FQ",
        "outputId": "39f8c949-b28b-41a2-9b6b-0b581223f7a7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello  helloworld.cu  myfile  myfile.cu  sample_data\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "% → Runs special notebook commands for one line.\n"
      ],
      "metadata": {
        "id": "OuwvL7oj0Fba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit sum(range(1000))\n",
        "%pwd\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "_jTD3dGk0FMj",
        "outputId": "3a56d52f-ac77-4b4a-d7d6-b532bf2fec85"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19.5 µs ± 4.4 µs per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "%% → Applies to the entire cell."
      ],
      "metadata": {
        "id": "TXf3Mljk0Q6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for i in range(1000000):\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ta_zv4MKzyj2",
        "outputId": "e4579a68-ce2d-410d-a429-ee0b6bf8703a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 39.1 ms, sys: 19 µs, total: 39.1 ms\n",
            "Wall time: 39 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Identify all key nvidia-smi commands with multiple options"
      ],
      "metadata": {
        "id": "sUAda77QvuHs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcU1oKAAur-n",
        "outputId": "fb4c8461-e4db-44b1-9c25-0ded968820c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Feb 14 15:47:37 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Command\tPurpose\n",
        "\n",
        "nvidia-smi -L\t-> List all GPUs\n",
        "\n",
        "nvidia-smi -q\t-> Detailed GPU info\n",
        "\n",
        "nvidia-smi -q -d -> MEMORY\tMemory details\n",
        "\n",
        "nvidia-smi --help\t-> Show help\n",
        "\n",
        "nvidia-smi -l 1\t-> Refresh every 1 sec\n",
        "\n",
        "nvidia-smi --query-gpu=name,memory.total,memory.used --format=csv\t-> Custom query\n",
        "\n",
        "nvidia-smi topo -m\t-> GPU topology"
      ],
      "metadata": {
        "id": "Tm6PHCXpu8ve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Debug common CUDA errors (zero output, incorrect indexing, PTX errors"
      ],
      "metadata": {
        "id": "K7TMomnu0mKK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Zero Output\n",
        "\n",
        "Cause:\n",
        "\n",
        "Forgot cudaMemcpy\n",
        "\n",
        "Wrong kernel launch\n",
        "\n",
        "Not using __global__\n",
        "\n",
        "2. Incorrect Indexing\n",
        "\n",
        "Wrong:\n",
        "\n",
        "int id = threadIdx.x;\n",
        "\n",
        "Correct:\n",
        "\n",
        "int id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "3. PTX Errors\n",
        "\n",
        "Cause:\n",
        "\n",
        "CUDA version mismatch\n",
        "\n",
        "Wrong architecture"
      ],
      "metadata": {
        "id": "6CCrkFKl0zDN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Write a CUDA C/C++ program to demonstrate GPU kernel execution and thread indexing.\n",
        "a. Launch a CUDA kernel using: 1 block and 8 threads\n",
        "\n",
        "b. Each thread must print: Hello from GPU thread <global_thread_id>\n",
        "\n",
        "c. Compute the global thread ID using: global_thread_id = blockIdx.x * blockDim.x +\n",
        "threadIdx.x\n",
        "\n",
        "d. Clearly separate: Host code (CPU) & Device code (GPU kernel)"
      ],
      "metadata": {
        "id": "ip5179Fcv9lx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile helloworld.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "\n",
        "__global__ void hello(){\n",
        "  int global_thread_id=blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    printf(\"Hello from GPU thread %d\\n\",global_thread_id);\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  printf(\"This is CPU launching kernel\\n\");\n",
        "  hello<<<1,8>>>();\n",
        "  cudaDeviceSynchronize();\n",
        "  printf(\"This is CPU again, kernel execution finished.\\n\");\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuJ4bIHzu250",
        "outputId": "fc582500-d0fd-4d94-a786-2da6acf0b0f5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting helloworld.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 helloworld.cu -o hello"
      ],
      "metadata": {
        "id": "SxVUwq2Ow-gB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ./hello"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaRu7Q_1xJoH",
        "outputId": "d1af93fc-2aa7-4776-edde-0462fcbf7afd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is CPU launching kernel\n",
            "Hello from GPU thread 0\n",
            "Hello from GPU thread 1\n",
            "Hello from GPU thread 2\n",
            "Hello from GPU thread 3\n",
            "Hello from GPU thread 4\n",
            "Hello from GPU thread 5\n",
            "Hello from GPU thread 6\n",
            "Hello from GPU thread 7\n",
            "This is CPU again, kernel execution finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Write a CUDA program to demonstrate host and device memory separation.\n",
        "a. Create an integer array of size 5 on the host (CPU).\n",
        "\n",
        "b. Allocate corresponding memory on the device (GPU) using cudaMalloc().\n",
        "\n",
        "c. Copy data from host to device using cudaMemcpy().\n",
        "\n",
        "d. Launch a kernel where GPU threads print values from device memory.\n",
        "\n",
        "e. Copy the data back from device to host and print it on CPU."
      ],
      "metadata": {
        "id": "dPIEjJ4Mxvp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile myfile.cu\n",
        "#include<stdio.h>\n",
        "\n",
        "__global__ void printarray(int *d_arr){\n",
        "  int id=threadIdx.x;\n",
        "  printf(\"GPU thread %d, Value= %d\\n\",id,d_arr[id]);\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  int h_arr[5]={10,20,30,40,50};\n",
        "  int *d_arr;\n",
        "  int size=5*sizeof(int);\n",
        "\n",
        "  cudaMalloc((void**)&d_arr,size);\n",
        "  cudaMemcpy(d_arr,h_arr,size,cudaMemcpyHostToDevice);\n",
        "  printarray<<<1, 5>>>(d_arr);\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  cudaMemcpy(h_arr, d_arr, size, cudaMemcpyDeviceToHost);\n",
        "  printf(\"\\nBack on CPU:\\n\");\n",
        "  for(int i = 0; i < 5; i++) {\n",
        "    printf(\"h_arr[%d] = %d\\n\", i, h_arr[i]);\n",
        "  }\n",
        "  cudaFree(d_arr);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQUKCp7CxlqR",
        "outputId": "08e3b4d2-3b2b-45d3-8aef-bd7c4dab6706"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting myfile.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 myfile.cu -o myfile"
      ],
      "metadata": {
        "id": "4VO_eyw6y_Om"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ./myfile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8hbRJO1zEhd",
        "outputId": "32d646e6-04ba-411e-e1af-84f1de7df345"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU thread 0, Value= 10\n",
            "GPU thread 1, Value= 20\n",
            "GPU thread 2, Value= 30\n",
            "GPU thread 3, Value= 40\n",
            "GPU thread 4, Value= 50\n",
            "\n",
            "Back on CPU:\n",
            "h_arr[0] = 10\n",
            "h_arr[1] = 20\n",
            "h_arr[2] = 30\n",
            "h_arr[3] = 40\n",
            "h_arr[4] = 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Compare CPU times of List/tuple with Numpy arrays."
      ],
      "metadata": {
        "id": "dW1MQe0Pzaor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "size = 10_000_000\n",
        "\n",
        "# Python List\n",
        "start = time.time()\n",
        "lst = list(range(size))\n",
        "lst = [x + 1 for x in lst]\n",
        "end = time.time()\n",
        "print(\"List Time:\", end - start)\n",
        "\n",
        "# Python Tuple\n",
        "start = time.time()\n",
        "tpl = tuple(range(size))\n",
        "tpl = tuple(x + 1 for x in tpl)\n",
        "end = time.time()\n",
        "print(\"Tuple Time:\", end - start)\n",
        "\n",
        "# NumPy Array\n",
        "start = time.time()\n",
        "arr = np.arange(size)\n",
        "arr = arr + 1\n",
        "end = time.time()\n",
        "print(\"NumPy Time:\", end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esAMpgipzNhr",
        "outputId": "7e3438d2-91f2-4d96-b73f-0929fbd40471"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List Time: 0.7632122039794922\n",
            "Tuple Time: 0.9661605358123779\n",
            "NumPy Time: 0.043309926986694336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NumPy → Very Fast (vectorized operations in C)"
      ],
      "metadata": {
        "id": "RIVrjLfNzp9M"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "87SvvZ6Aznra"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}