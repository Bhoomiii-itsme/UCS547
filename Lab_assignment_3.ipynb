{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Write a CUDA C/C++ program to perform element-wise addition of two vectors.\n",
        "C[i]=A[i]+B[i]\n",
        "\n",
        "Given: Vector size: N = 1024"
      ],
      "metadata": {
        "id": "wcEIyh6G4X94"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VI7KIY5Z2row",
        "outputId": "428204aa-197f-4960-b4e1-b83a09a5f855"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vector_addition.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile vector_addition.cu\n",
        "#include<stdio.h>\n",
        "#define N 1024\n",
        "\n",
        "__global__ void vectoradd(int *a,int*b,int*c){\n",
        "  int i=blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  c[i]=a[i]+b[i];\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  int a[N],b[N],c[N];\n",
        "  int *d_a,*d_b,*d_c;\n",
        "  for (int i=0;i<N;i++){\n",
        "    a[i]=i;\n",
        "    b[i]=2*i;\n",
        "  }\n",
        "  int size=N*sizeof(int);\n",
        "  cudaMalloc((void**)&d_a,size);\n",
        "  cudaMalloc((void**)&d_b,size);\n",
        "  cudaMalloc((void**)&d_c,size);\n",
        "\n",
        "  cudaMemcpy(d_a,a,size,cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_b,b,size,cudaMemcpyHostToDevice);\n",
        "  vectoradd<<<N/256,256>>>(d_a,d_b,d_c);\n",
        "\n",
        "  cudaMemcpy(c,d_c,size,cudaMemcpyDeviceToHost);\n",
        "  printf(\"First 10 results:\\n\");\n",
        "  for (int i=0;i<10;i++){\n",
        "    printf(\"%d\\n\",c[i]);\n",
        "  }\n",
        "  cudaFree(d_a);\n",
        "  cudaFree(d_b);\n",
        "  cudaFree(d_c);\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! nvcc -arch=sm_75 vector_addition.cu -o add"
      ],
      "metadata": {
        "id": "wgqXpdAc4dfF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ./add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hNydm454r28",
        "outputId": "f90cf6fe-9ccb-4a83-b83f-14a1485fddfe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 results:\n",
            "0\n",
            "3\n",
            "6\n",
            "9\n",
            "12\n",
            "15\n",
            "18\n",
            "21\n",
            "24\n",
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Perform the same vector additon as in Q1 using Thrust library only"
      ],
      "metadata": {
        "id": "2VNeGujq5Fa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile add.cu\n",
        "\n",
        "#include <thrust/host_vector.h>\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/transform.h>\n",
        "#include <iostream>\n",
        "#define N 1024\n",
        "\n",
        "int main(){\n",
        "\n",
        "  thrust::host_vector<float> h_a(N);\n",
        "  thrust::host_vector<float> h_b(N);\n",
        "  for (int i=0;i<N;i++){\n",
        "    h_a[i]=i;\n",
        "    h_b[i]=2*i;\n",
        "  }\n",
        "  thrust::device_vector<int>a=h_a;\n",
        "  thrust::device_vector<int>b=h_b;\n",
        "  thrust::device_vector<int>c(N);\n",
        "  thrust::transform(a.begin(),a.end(),b.begin(),c.begin(),thrust::plus<int>());\n",
        "  thrust::host_vector<int>h_c=c;\n",
        "  printf(\"First 10 results:\\n\");\n",
        "  for (int i=0;i<10;i++){\n",
        "    printf(\"%d\\n\",h_c[i]);\n",
        "  }\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWV26xjk42dB",
        "outputId": "492c4b5d-0aaa-43d4-8797-9cc2931a6dbc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 add.cu -o add"
      ],
      "metadata": {
        "id": "yshRnieX7YZb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ./add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u9gwRrY7c5N",
        "outputId": "b674b41b-8bda-4abe-c5d9-799abc531b0a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 results:\n",
            "0\n",
            "3\n",
            "6\n",
            "9\n",
            "12\n",
            "15\n",
            "18\n",
            "21\n",
            "24\n",
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Compute the dot product of two vectors of size, N =1024: Result=∑A[i]×B[i] using Thrust and compare its performance with that on CPU."
      ],
      "metadata": {
        "id": "Lq2oquwhBS1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile inner_product.cu\n",
        "\n",
        "#include <thrust/host_vector.h>\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/inner_product.h>\n",
        "#include <iostream>\n",
        "#include <chrono>\n",
        "#define N 1024\n",
        "\n",
        "int main(){\n",
        "  thrust::host_vector<int> h_a(N);\n",
        "  thrust::host_vector<int> h_b(N);\n",
        "  for (int i=0;i<N;i++){\n",
        "    h_a[i]=i;\n",
        "    h_b[i]=2*i;\n",
        "  }\n",
        "\n",
        "  auto cpu_start = std::chrono::high_resolution_clock::now();\n",
        "  int cpu_result = 0;\n",
        "  for(int i=0;i<N;i++){\n",
        "      cpu_result += h_a[i] * h_b[i];\n",
        "  }\n",
        "  auto cpu_end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "  auto start = std::chrono::high_resolution_clock::now();\n",
        "  thrust::device_vector<int>a=h_a;\n",
        "  thrust::device_vector<int>b=h_b;\n",
        "  int result = thrust::inner_product(a.begin(),a.end(),b.begin(),0);\n",
        "  auto end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "  std::cout << \"CPU Dot Product = \" << cpu_result <<std::endl;\n",
        "  std::cout << \"CPU Time = \"\n",
        "            << std::chrono::duration<double, std::milli>(cpu_end - cpu_start).count()\n",
        "            << \" ms\\n\";\n",
        "\n",
        "  std::cout << \"\\nGPU Dot Product = \" << result << std::endl;\n",
        "  std::cout << \"GPU Time: \" << std::chrono::duration<double, std::milli>(end-start).count() <<\" ms\\n\";\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YH6Rrd1m71Ze",
        "outputId": "f664168e-4d89-484e-acfc-220162a0149c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting inner_product.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " for int result -> The computation happens on GPU, but the final scalar result is copied back and stored in host memory."
      ],
      "metadata": {
        "id": "ksezLfnoCbzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 inner_product.cu -o inner_prod"
      ],
      "metadata": {
        "id": "HKHjd2LRCRqP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ./inner_prod"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te7C7FMYCW1p",
        "outputId": "ba8c363d-4ed4-466a-f4c1-7b16ddbf15ab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU Dot Product = 714779648\n",
            "CPU Time = 0.127337 ms\n",
            "\n",
            "GPU Dot Product = 714779648\n",
            "GPU Time: 283.062 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Write a CUDA kernel for matrix multiplication: C=A×B where Matrix size is 16 X 16. Explain why matrix multiplication needs more computation than addition (as in Q1)."
      ],
      "metadata": {
        "id": "qvvdSobgEquh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_multiplication.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define N 16\n",
        "\n",
        "__global__ void matrixMul(float *A, float *B, float *C)\n",
        "{\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    float sum = 0.0f;\n",
        "\n",
        "    for (int k=0;k<N;k++)\n",
        "    {\n",
        "        sum+=A[row*N+k]*B[k*N+col];\n",
        "    }\n",
        "\n",
        "    C[row*N+col]=sum;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    float A[N][N], B[N][N], C[N][N];\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "\n",
        "    for(int i=0;i<N;i++)\n",
        "    {\n",
        "        for(int j=0;j<N;j++)\n",
        "        {\n",
        "            A[i][j]=i+j;\n",
        "            B[i][j]=1;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    cudaMalloc((void**)&d_A, N*N*sizeof(float));\n",
        "    cudaMalloc((void**)&d_B, N*N*sizeof(float));\n",
        "    cudaMalloc((void**)&d_C, N*N*sizeof(float));\n",
        "\n",
        "    cudaMemcpy(d_A, A, N*N*sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, B, N*N*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 threadsPerBlock(16,16);\n",
        "    dim3 blocksPerGrid(1,1);\n",
        "\n",
        "    matrixMul<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C);\n",
        "\n",
        "    cudaMemcpy(C, d_C, N*N*sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Result Matrix C:\\n\");\n",
        "    for(int i=0;i<N;i++)\n",
        "    {\n",
        "        for(int j=0;j<N;j++)\n",
        "        {\n",
        "            printf(\"%6.1f \",C[i][j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrkuUSfgC3AT",
        "outputId": "7b16dffe-f1bb-4280-8292-e3b425377bc2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrix_multiplication.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 matrix_multiplication.cu -o matrix_multiplication"
      ],
      "metadata": {
        "id": "4gCD8q4DD2ac"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ./matrix_multiplication"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HF5IRe5BD8ZJ",
        "outputId": "b37fd159-0fe5-42a7-ed1e-3c43b4e31de0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result Matrix C:\n",
            " 120.0  120.0  120.0  120.0  120.0  120.0  120.0  120.0  120.0  120.0  120.0  120.0  120.0  120.0  120.0  120.0 \n",
            " 136.0  136.0  136.0  136.0  136.0  136.0  136.0  136.0  136.0  136.0  136.0  136.0  136.0  136.0  136.0  136.0 \n",
            " 152.0  152.0  152.0  152.0  152.0  152.0  152.0  152.0  152.0  152.0  152.0  152.0  152.0  152.0  152.0  152.0 \n",
            " 168.0  168.0  168.0  168.0  168.0  168.0  168.0  168.0  168.0  168.0  168.0  168.0  168.0  168.0  168.0  168.0 \n",
            " 184.0  184.0  184.0  184.0  184.0  184.0  184.0  184.0  184.0  184.0  184.0  184.0  184.0  184.0  184.0  184.0 \n",
            " 200.0  200.0  200.0  200.0  200.0  200.0  200.0  200.0  200.0  200.0  200.0  200.0  200.0  200.0  200.0  200.0 \n",
            " 216.0  216.0  216.0  216.0  216.0  216.0  216.0  216.0  216.0  216.0  216.0  216.0  216.0  216.0  216.0  216.0 \n",
            " 232.0  232.0  232.0  232.0  232.0  232.0  232.0  232.0  232.0  232.0  232.0  232.0  232.0  232.0  232.0  232.0 \n",
            " 248.0  248.0  248.0  248.0  248.0  248.0  248.0  248.0  248.0  248.0  248.0  248.0  248.0  248.0  248.0  248.0 \n",
            " 264.0  264.0  264.0  264.0  264.0  264.0  264.0  264.0  264.0  264.0  264.0  264.0  264.0  264.0  264.0  264.0 \n",
            " 280.0  280.0  280.0  280.0  280.0  280.0  280.0  280.0  280.0  280.0  280.0  280.0  280.0  280.0  280.0  280.0 \n",
            " 296.0  296.0  296.0  296.0  296.0  296.0  296.0  296.0  296.0  296.0  296.0  296.0  296.0  296.0  296.0  296.0 \n",
            " 312.0  312.0  312.0  312.0  312.0  312.0  312.0  312.0  312.0  312.0  312.0  312.0  312.0  312.0  312.0  312.0 \n",
            " 328.0  328.0  328.0  328.0  328.0  328.0  328.0  328.0  328.0  328.0  328.0  328.0  328.0  328.0  328.0  328.0 \n",
            " 344.0  344.0  344.0  344.0  344.0  344.0  344.0  344.0  344.0  344.0  344.0  344.0  344.0  344.0  344.0  344.0 \n",
            " 360.0  360.0  360.0  360.0  360.0  360.0  360.0  360.0  360.0  360.0  360.0  360.0  360.0  360.0  360.0  360.0 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Case 1: Matrix Addition (16 × 16)__\n",
        "\n",
        "Formula: C[i][j]=A[i][j]+B[i][j]\n",
        "\n",
        "For each element: Only 1 addition\n",
        "\n",
        "Total operations: 16×16=256 additions\n",
        "\n",
        "Time complexity:O(N^2)\n",
        "\n",
        "__Case 2: Matrix Multiplication (16 × 16)__\n",
        "\n",
        "Formula: C[i][j]= k=0∑15 A[i][k]×B[k][j]\n",
        "\n",
        "For each element: 16 multiplications and 15 additions\n",
        "\n",
        "Total elements: 16×16=256\n",
        "\n",
        "Total operations: 256×16=4096 multiplications\n",
        "\n",
        "Time complexity:O(N^3)"
      ],
      "metadata": {
        "id": "lM65kEIoE8ug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. For vector addition of size 5,000,000, implement and compare:\n",
        "\n",
        "• CPU sequential C/C++ program\n",
        "\n",
        "• CUDA kernel implementation\n",
        "\n",
        "• Thrust implementation\n",
        "\n",
        "• RAPIDS implementation\n",
        "\n",
        "Measure execution time and compare complexity for each approach and\n",
        "present results in a table. Plot comparison graph."
      ],
      "metadata": {
        "id": "3wHC5uT-Gt_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cpu_vector_add.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <chrono>\n",
        "\n",
        "#define N 5000000\n",
        "\n",
        "int main() {\n",
        "\n",
        "    std::vector<float> A(N, 1.0f);\n",
        "    std::vector<float> B(N, 2.0f);\n",
        "    std::vector<float> C(N);\n",
        "\n",
        "    auto start = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    for(int i = 0; i < N; i++)\n",
        "        C[i] = A[i] + B[i];\n",
        "\n",
        "    auto end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    std::cout << \"CPU Time: \"\n",
        "              << std::chrono::duration<double, std::milli>(end-start).count()\n",
        "              << \" ms\\n\";\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzvZ3x92D_GD",
        "outputId": "f9ffacd6-bbd3-4177-a150-692626ff92a3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cpu_vector_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 cpu_vector_add.cu -o cpu_vector_add"
      ],
      "metadata": {
        "id": "vN1j43cHIzN7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ./cpu_vector_add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW8owJKwI9-N",
        "outputId": "e432f467-2a44-4e1d-93a2-2e398ebe1129"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU Time: 37.7338 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cuda_vector_add.cu\n",
        "#include<stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <chrono>\n",
        "#include <iostream>\n",
        "\n",
        "#define N 5000000\n",
        "\n",
        "__global__ void vectoradd(int *a,int*b,int*c){\n",
        "  int i=blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  if(i < N)\n",
        "    c[i]=a[i]+b[i];\n",
        "}\n",
        "\n",
        "int main(){\n",
        "\n",
        "  int *a = new int[N];\n",
        "  int *b = new int[N];\n",
        "  int *c = new int[N];\n",
        "\n",
        "  int *d_a,*d_b,*d_c;\n",
        "\n",
        "  for (int i=0;i<N;i++){\n",
        "    a[i]=i;\n",
        "    b[i]=2*i;\n",
        "  }\n",
        "\n",
        "  int size=N*sizeof(int);\n",
        "\n",
        "  cudaMalloc((void**)&d_a,size);\n",
        "  cudaMalloc((void**)&d_b,size);\n",
        "  cudaMalloc((void**)&d_c,size);\n",
        "\n",
        "  int blockSize = 256;\n",
        "  int gridSize = (N + blockSize - 1) / blockSize;\n",
        "\n",
        "  auto start = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "  cudaMemcpy(d_a,a,size,cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_b,b,size,cudaMemcpyHostToDevice);\n",
        "\n",
        "  vectoradd<<<gridSize,blockSize>>>(d_a,d_b,d_c);\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  cudaMemcpy(c,d_c,size,cudaMemcpyDeviceToHost);\n",
        "\n",
        "  auto end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "  printf(\"First 10 results:\\n\");\n",
        "  for (int i=0;i<10;i++){\n",
        "    printf(\"%d\\n\",c[i]);\n",
        "  }\n",
        "\n",
        "  std::cout << \"CUDA Time: \"\n",
        "            << std::chrono::duration<double, std::milli>(end-start).count()\n",
        "            << \" ms\\n\";\n",
        "\n",
        "  cudaFree(d_a);\n",
        "  cudaFree(d_b);\n",
        "  cudaFree(d_c);\n",
        "\n",
        "  delete[] a;\n",
        "  delete[] b;\n",
        "  delete[] c;\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5T72ZTCHMyI",
        "outputId": "69e19e91-6acc-4cfe-d131-966b1abcdc02"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cuda_vector_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 cuda_vector_add.cu -o cuda_vector_add"
      ],
      "metadata": {
        "id": "ZXNZ6c8iI0Xg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ./cuda_vector_add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHo7j7pbJrIH",
        "outputId": "75a576d4-8558-4148-a285-e46dcabc7d50"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 results:\n",
            "0\n",
            "3\n",
            "6\n",
            "9\n",
            "12\n",
            "15\n",
            "18\n",
            "21\n",
            "24\n",
            "27\n",
            "CUDA Time: 24.9006 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile add.cu\n",
        "\n",
        "#include <thrust/host_vector.h>\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/transform.h>\n",
        "#include <chrono>\n",
        "#include <iostream>\n",
        "#define N 5000000\n",
        "\n",
        "int main(){\n",
        "\n",
        "  thrust::host_vector<float> h_a(N);\n",
        "  thrust::host_vector<float> h_b(N);\n",
        "  for (int i=0;i<N;i++){\n",
        "    h_a[i]=i;\n",
        "    h_b[i]=2*i;\n",
        "  }\n",
        "\n",
        "  {\n",
        "    thrust::device_vector<float> warm_a = h_a;\n",
        "    thrust::device_vector<float> warm_b = h_b;\n",
        "    thrust::device_vector<float> warm_c(N);\n",
        "\n",
        "    thrust::transform(warm_a.begin(),\n",
        "                        warm_a.end(),\n",
        "                        warm_b.begin(),\n",
        "                        warm_c.begin(),\n",
        "                        thrust::plus<float>());\n",
        "\n",
        "    cudaDeviceSynchronize();   // Ensure GPU finished\n",
        "  }\n",
        "\n",
        "  auto start = std::chrono::high_resolution_clock::now();\n",
        "  thrust::device_vector<int>a=h_a;\n",
        "  thrust::device_vector<int>b=h_b;\n",
        "  thrust::device_vector<int>c(N);\n",
        "  thrust::transform(a.begin(),a.end(),b.begin(),c.begin(),thrust::plus<int>());\n",
        "  thrust::host_vector<int>h_c=c;\n",
        "  auto end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "  printf(\"First 10 results:\\n\");\n",
        "  for (int i=0;i<10;i++){\n",
        "    printf(\"%d\\n\",h_c[i]);\n",
        "  }\n",
        "\n",
        "  std::cout << \"Thrust Time:\"\n",
        "              << std::chrono::duration<double, std::milli>(end-start).count()\n",
        "              << \" ms\\n\";\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_nUyFRcHkre",
        "outputId": "4325076c-ff3f-41bf-b93b-1880f4323e37"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 add.cu -o add"
      ],
      "metadata": {
        "id": "i2MEIjPWI1Pa"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ./add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4kiqdmPJ4U5",
        "outputId": "23e04f20-ba7b-4886-da87-1c8f76d885d3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 results:\n",
            "0\n",
            "3\n",
            "6\n",
            "9\n",
            "12\n",
            "15\n",
            "18\n",
            "21\n",
            "24\n",
            "27\n",
            "Thrust Time:676.17 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rapids_vector_add.py\n",
        "import cupy as cp\n",
        "import time\n",
        "\n",
        "N = 5_000_000\n",
        "\n",
        "A = cp.ones(N, dtype=cp.float32)\n",
        "B = cp.full(N, 2.0, dtype=cp.float32)\n",
        "\n",
        "_ = A + B\n",
        "cp.cuda.Stream.null.synchronize()\n",
        "\n",
        "start = time.time()\n",
        "C = A + B\n",
        "cp.cuda.Stream.null.synchronize()\n",
        "end = time.time()\n",
        "\n",
        "print(\"RAPIDS (CuPy) Time:\", (end - start) * 1000, \"ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDaroueiIrGf",
        "outputId": "b5984ce3-43d9-4ba8-9585-c6af988db688"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAPIDS (CuPy) Time: 0.48828125 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Write a CUDA C++ program using the Thrust library to compute the sum of all elements in a vector stored on the GPU. The vector is of size 10 and it should be initialized with values 1,…..10"
      ],
      "metadata": {
        "id": "0OR_1mvfKJF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile thrust_sum.cu\n",
        "\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/reduce.h>\n",
        "#include <iostream>\n",
        "\n",
        "int main()\n",
        "{\n",
        "    const int N = 10;\n",
        "    thrust::device_vector<int> d_vec(N);\n",
        "    for(int i=0;i<N;i++)\n",
        "    {\n",
        "        d_vec[i]=i+1;\n",
        "    }\n",
        "    int sum = thrust::reduce(d_vec.begin(),\n",
        "                             d_vec.end(),\n",
        "                             0,\n",
        "                             thrust::plus<int>());\n",
        "\n",
        "    std::cout << \"Sum of elements (1 to 10) = \" << sum << std::endl;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaKsVEbtJ_N2",
        "outputId": "1fff5330-5499-4182-a37e-c3ff3142fc70"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting thrust_sum.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 thrust_sum.cu -o thrust_sum"
      ],
      "metadata": {
        "id": "W3KAneavKhW_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ./thrust_sum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN2tYYE8Kmu7",
        "outputId": "cf6856e0-7451-4f15-fb60-2bce68af905a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of elements (1 to 10) = 55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Write a CUDA C++ program using Thrust to sort (ascending) a vector of integers on the GPU. Consider vector size 8 with following values: 7, 2, 9, 1, 5, 3, 8, 4. Print the vector before and afer sorting"
      ],
      "metadata": {
        "id": "jwNkoSmILXfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile thrust_sort.cu\n",
        "\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/host_vector.h>\n",
        "#include <thrust/sort.h>\n",
        "#include <iostream>\n",
        "\n",
        "int main()\n",
        "{\n",
        "    const int N = 8;\n",
        "    thrust::host_vector<int> h_vec(N);\n",
        "\n",
        "    int values[N] = {7, 2, 9, 1, 5, 3, 8, 4};\n",
        "\n",
        "    for(int i = 0; i < N; i++)\n",
        "        h_vec[i] = values[i];\n",
        "\n",
        "    std::cout << \"Before Sorting:\\n\";\n",
        "    for(int i = 0; i < N; i++)\n",
        "        std::cout << h_vec[i] << \" \";\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    thrust::device_vector<int> d_vec = h_vec;\n",
        "    thrust::sort(d_vec.begin(), d_vec.end());\n",
        "    h_vec = d_vec;\n",
        "\n",
        "    std::cout << \"After Sorting (Ascending):\\n\";\n",
        "    for(int i = 0; i < N; i++)\n",
        "        std::cout << h_vec[i] << \" \";\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t74MhP0GKqcA",
        "outputId": "79495c6b-5dd9-4b2c-bc7a-3fb505322cec"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting thrust_sort.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 thrust_sort.cu -o thrust_sort"
      ],
      "metadata": {
        "id": "PYMWIGZKK9rd"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ./thrust_sort"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C968OvBLCrR",
        "outputId": "f7241d9f-c156-46fd-d98b-b32726be20f2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Sorting:\n",
            "7 2 9 1 5 3 8 4 \n",
            "After Sorting (Ascending):\n",
            "1 2 3 4 5 7 8 9 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fXlgQVFDLGhp"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}