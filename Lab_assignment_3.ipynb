{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Write a CUDA C/C++ program to perform element-wise addition of two vectors.\n",
        "C[i]=A[i]+B[i]\n",
        "\n",
        "Given: Vector size: N = 1024"
      ],
      "metadata": {
        "id": "wcEIyh6G4X94"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VI7KIY5Z2row",
        "outputId": "07a7d8cf-d57e-4aee-8c62-3b457fc69919"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vector_addition.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile vector_addition.cu\n",
        "#include<stdio.h>\n",
        "#define N 1024\n",
        "\n",
        "__global__ void vectoradd(int *a,int*b,int*c){\n",
        "  int i=blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  c[i]=a[i]+b[i];\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  int a[N],b[N],c[N];\n",
        "  int *d_a,*d_b,*d_c;\n",
        "  for (int i=0;i<N;i++){\n",
        "    a[i]=i;\n",
        "    b[i]=2*i;\n",
        "  }\n",
        "  int size=N*sizeof(int);\n",
        "  cudaMalloc((void**)&d_a,size);\n",
        "  cudaMalloc((void**)&d_b,size);\n",
        "  cudaMalloc((void**)&d_c,size);\n",
        "\n",
        "  cudaMemcpy(d_a,a,size,cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_b,b,size,cudaMemcpyHostToDevice);\n",
        "  vectoradd<<<N/256,256>>>(d_a,d_b,d_c);\n",
        "\n",
        "  cudaMemcpy(c,d_c,size,cudaMemcpyDeviceToHost);\n",
        "  printf(\"First 10 results:\\n\");\n",
        "  for (int i=0;i<10;i++){\n",
        "    printf(\"%d\\n\",c[i]);\n",
        "  }\n",
        "  cudaFree(d_a);\n",
        "  cudaFree(d_b);\n",
        "  cudaFree(d_c);\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! nvcc -arch=sm_75 vector_addition.cu -o add"
      ],
      "metadata": {
        "id": "wgqXpdAc4dfF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ./add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hNydm454r28",
        "outputId": "c7cb6eab-dd3e-4a92-bc7f-d5d4b581a839"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 results:\n",
            "0\n",
            "3\n",
            "6\n",
            "9\n",
            "12\n",
            "15\n",
            "18\n",
            "21\n",
            "24\n",
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Perform the same vector additon as in Q1 using Thrust library only"
      ],
      "metadata": {
        "id": "2VNeGujq5Fa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile add.cu\n",
        "\n",
        "#include <thrust/host_vector.h>\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/transform.h>\n",
        "#include <iostream>\n",
        "#define N 1024\n",
        "\n",
        "int main(){\n",
        "\n",
        "  thrust::host_vector<float> h_a(N);\n",
        "  thrust::host_vector<float> h_b(N);\n",
        "  for (int i=0;i<N;i++){\n",
        "    h_a[i]=i;\n",
        "    h_b[i]=2*i;\n",
        "  }\n",
        "  thrust::device_vector<int>a=h_a;\n",
        "  thrust::device_vector<int>b=h_b;\n",
        "  thrust::device_vector<int>c(N);\n",
        "  thrust::transform(a.begin(),a.end(),b.begin(),c.begin(),thrust::plus<int>());\n",
        "  thrust::host_vector<int>h_c=c;\n",
        "  printf(\"First 10 results:\\n\");\n",
        "  for (int i=0;i<10;i++){\n",
        "    printf(\"%d\\n\",h_c[i]);\n",
        "  }\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWV26xjk42dB",
        "outputId": "4b890ec9-147b-4548-bd26-7f98b9b52d5f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 add.cu -o add"
      ],
      "metadata": {
        "id": "yshRnieX7YZb"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ./add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u9gwRrY7c5N",
        "outputId": "df47c972-2515-48ea-8ad2-26ef32a87afc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 results:\n",
            "0\n",
            "3\n",
            "6\n",
            "9\n",
            "12\n",
            "15\n",
            "18\n",
            "21\n",
            "24\n",
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Compute the dot product of two vectors of size, N =1024: Result=∑A[i]×B[i] using Thrust and compare its performance with that on CPU."
      ],
      "metadata": {
        "id": "Lq2oquwhBS1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile inner_product.cu\n",
        "\n",
        "#include <thrust/host_vector.h>\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/inner_product.h>\n",
        "#include <iostream>\n",
        "#include <chrono>\n",
        "#define N 1024\n",
        "\n",
        "int main(){\n",
        "  thrust::host_vector<int> h_a(N);\n",
        "  thrust::host_vector<int> h_b(N);\n",
        "  for (int i=0;i<N;i++){\n",
        "    h_a[i]=i;\n",
        "    h_b[i]=2*i;\n",
        "  }\n",
        "\n",
        "  auto cpu_start = std::chrono::high_resolution_clock::now();\n",
        "  int cpu_result = 0;\n",
        "  for(int i=0;i<N;i++){\n",
        "      cpu_result += h_a[i] * h_b[i];\n",
        "  }\n",
        "  auto cpu_end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "  auto start = std::chrono::high_resolution_clock::now();\n",
        "  thrust::device_vector<int>a=h_a;\n",
        "  thrust::device_vector<int>b=h_b;\n",
        "  int result = thrust::inner_product(a.begin(),a.end(),b.begin(),0);\n",
        "  auto end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "  std::cout << \"CPU Dot Product = \" << cpu_result <<std::endl;\n",
        "  std::cout << \"CPU Time = \"\n",
        "            << std::chrono::duration<double, std::milli>(cpu_end - cpu_start).count()\n",
        "            << \" ms\\n\";\n",
        "\n",
        "  std::cout << \"\\nGPU Dot Product = \" << result << std::endl;\n",
        "  std::cout << \"GPU Time: \" << std::chrono::duration<double, std::milli>(end-start).count() <<\" ms\\n\";\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YH6Rrd1m71Ze",
        "outputId": "d3bc1184-cd91-4d38-dcf0-173e1b041989"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting inner_product.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " for int result -> The computation happens on GPU, but the final scalar result is copied back and stored in host memory."
      ],
      "metadata": {
        "id": "ksezLfnoCbzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 inner_product.cu -o inner_prod"
      ],
      "metadata": {
        "id": "HKHjd2LRCRqP"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ./inner_prod"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te7C7FMYCW1p",
        "outputId": "7db257fb-f54e-45ee-ad8e-29236954e03a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU Dot Product = 714779648\n",
            "CPU Time = 0.077322 ms\n",
            "\n",
            "GPU Dot Product = 714779648\n",
            "GPU Time: 0.659702 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Write a CUDA kernel for matrix multiplication: C=A×B where Matrix size is 16 X 16. Explain why matrix multiplication needs more computation than addition (as in Q1)."
      ],
      "metadata": {
        "id": "qvvdSobgEquh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_multiplication.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define N 16\n",
        "\n",
        "__global__ void matrixMul(float *A, float *B, float *C)\n",
        "{\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    float sum = 0.0f;\n",
        "\n",
        "    for (int k=0;k<N;k++)\n",
        "    {\n",
        "        sum+=A[row*N+k]*B[k*N+col];\n",
        "    }\n",
        "\n",
        "    C[row*N+col]=sum;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    float A[N][N], B[N][N], C[N][N];\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "\n",
        "    for(inti=0;i<N;i++)\n",
        "    {\n",
        "        for(int j=0;j<N;j++)\n",
        "        {\n",
        "            A[i][j]=i+j;\n",
        "            B[i][j]=1;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    cudaMalloc((void**)&d_A, N*N*sizeof(float));\n",
        "    cudaMalloc((void**)&d_B, N*N*sizeof(float));\n",
        "    cudaMalloc((void**)&d_C, N*N*sizeof(float));\n",
        "\n",
        "    cudaMemcpy(d_A, A, N*N*sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, B, N*N*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 threadsPerBlock(16,16);\n",
        "    dim3 blocksPerGrid(1,1);\n",
        "\n",
        "    matrixMul<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C);\n",
        "\n",
        "    cudaMemcpy(C, d_C, N*N*sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Result Matrix C:\\n\");\n",
        "    for(int i=0;i<N;i++)\n",
        "    {\n",
        "        for(int j=0;j<N;j++)\n",
        "        {\n",
        "            printf(\"%6.1f \",C[i][j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrkuUSfgC3AT",
        "outputId": "5eaddcc4-97fd-41ed-ea72-6189667565ed"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrix_multiplication.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 matrix_multiplication.cu -o matrix_multiplication"
      ],
      "metadata": {
        "id": "4gCD8q4DD2ac"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ./matrix_multiplication"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HF5IRe5BD8ZJ",
        "outputId": "b953ef9c-a113-41f2-9d03-cd942667eb0c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result Matrix C:\n",
            " 120.0  120.0  120.0  120.0  120.0  120.0  120.0  120.0  120.0  120.0  120.0  120.0  120.0  120.0  120.0  120.0 \n",
            " 136.0  136.0  136.0  136.0  136.0  136.0  136.0  136.0  136.0  136.0  136.0  136.0  136.0  136.0  136.0  136.0 \n",
            " 152.0  152.0  152.0  152.0  152.0  152.0  152.0  152.0  152.0  152.0  152.0  152.0  152.0  152.0  152.0  152.0 \n",
            " 168.0  168.0  168.0  168.0  168.0  168.0  168.0  168.0  168.0  168.0  168.0  168.0  168.0  168.0  168.0  168.0 \n",
            " 184.0  184.0  184.0  184.0  184.0  184.0  184.0  184.0  184.0  184.0  184.0  184.0  184.0  184.0  184.0  184.0 \n",
            " 200.0  200.0  200.0  200.0  200.0  200.0  200.0  200.0  200.0  200.0  200.0  200.0  200.0  200.0  200.0  200.0 \n",
            " 216.0  216.0  216.0  216.0  216.0  216.0  216.0  216.0  216.0  216.0  216.0  216.0  216.0  216.0  216.0  216.0 \n",
            " 232.0  232.0  232.0  232.0  232.0  232.0  232.0  232.0  232.0  232.0  232.0  232.0  232.0  232.0  232.0  232.0 \n",
            " 248.0  248.0  248.0  248.0  248.0  248.0  248.0  248.0  248.0  248.0  248.0  248.0  248.0  248.0  248.0  248.0 \n",
            " 264.0  264.0  264.0  264.0  264.0  264.0  264.0  264.0  264.0  264.0  264.0  264.0  264.0  264.0  264.0  264.0 \n",
            " 280.0  280.0  280.0  280.0  280.0  280.0  280.0  280.0  280.0  280.0  280.0  280.0  280.0  280.0  280.0  280.0 \n",
            " 296.0  296.0  296.0  296.0  296.0  296.0  296.0  296.0  296.0  296.0  296.0  296.0  296.0  296.0  296.0  296.0 \n",
            " 312.0  312.0  312.0  312.0  312.0  312.0  312.0  312.0  312.0  312.0  312.0  312.0  312.0  312.0  312.0  312.0 \n",
            " 328.0  328.0  328.0  328.0  328.0  328.0  328.0  328.0  328.0  328.0  328.0  328.0  328.0  328.0  328.0  328.0 \n",
            " 344.0  344.0  344.0  344.0  344.0  344.0  344.0  344.0  344.0  344.0  344.0  344.0  344.0  344.0  344.0  344.0 \n",
            " 360.0  360.0  360.0  360.0  360.0  360.0  360.0  360.0  360.0  360.0  360.0  360.0  360.0  360.0  360.0  360.0 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Case 1: Matrix Addition (16 × 16)__\n",
        "\n",
        "Formula: C[i][j]=A[i][j]+B[i][j]\n",
        "\n",
        "For each element: Only 1 addition\n",
        "\n",
        "Total operations: 16×16=256 additions\n",
        "\n",
        "Time complexity:O(N^2)\n",
        "\n",
        "__Case 2: Matrix Multiplication (16 × 16)__\n",
        "\n",
        "Formula: C[i][j]= k=0∑15 A[i][k]×B[k][j]\n",
        "\n",
        "For each element: 16 multiplications and 15 additions\n",
        "\n",
        "Total elements: 16×16=256\n",
        "\n",
        "Total operations: 256×16=4096 multiplications\n",
        "\n",
        "Time complexity:O(N^3)"
      ],
      "metadata": {
        "id": "lM65kEIoE8ug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. For vector addition of size 5,000,000, implement and compare:\n",
        "\n",
        "• CPU sequential C/C++ program\n",
        "\n",
        "• CUDA kernel implementation\n",
        "\n",
        "• Thrust implementation\n",
        "\n",
        "• RAPIDS implementation\n",
        "\n",
        "Measure execution time and compare complexity for each approach and\n",
        "present results in a table. Plot comparison graph."
      ],
      "metadata": {
        "id": "3wHC5uT-Gt_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cpu_vector_add.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <chrono>\n",
        "\n",
        "#define N 5000000\n",
        "\n",
        "int main() {\n",
        "\n",
        "    std::vector<float> A(N, 1.0f);\n",
        "    std::vector<float> B(N, 2.0f);\n",
        "    std::vector<float> C(N);\n",
        "\n",
        "    auto start = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    for(int i = 0; i < N; i++)\n",
        "        C[i] = A[i] + B[i];\n",
        "\n",
        "    auto end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    std::cout << \"CPU Time: \"\n",
        "              << std::chrono::duration<double, std::milli>(end-start).count()\n",
        "              << \" ms\\n\";\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzvZ3x92D_GD",
        "outputId": "256fab42-a788-4746-c579-b0066d0c80ff"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cpu_vector_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 cpu_vector_add.cu -o cpu_vector_add"
      ],
      "metadata": {
        "id": "vN1j43cHIzN7"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ./cpu_vector_add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW8owJKwI9-N",
        "outputId": "be03ae2d-5339-4b58-c1c0-6db5f9d11c99"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU Time: 39.2713 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cuda_vector_add.cu\n",
        "#include<stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <chrono>\n",
        "#include <iostream>\n",
        "#define N 1024\n",
        "\n",
        "__global__ void vectoradd(int *a,int*b,int*c){\n",
        "  int i=blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  c[i]=a[i]+b[i];\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  int a[N],b[N],c[N];\n",
        "  int *d_a,*d_b,*d_c;\n",
        "  for (int i=0;i<N;i++){\n",
        "    a[i]=i;\n",
        "    b[i]=2*i;\n",
        "  }\n",
        "  int size=N*sizeof(int);\n",
        "  cudaMalloc((void**)&d_a,size);\n",
        "  cudaMalloc((void**)&d_b,size);\n",
        "  cudaMalloc((void**)&d_c,size);\n",
        "\n",
        "  auto start = std::chrono::high_resolution_clock::now();\n",
        "  cudaMemcpy(d_a,a,size,cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_b,b,size,cudaMemcpyHostToDevice);\n",
        "  vectoradd<<<N/256,256>>>(d_a,d_b,d_c);\n",
        "  cudaDeviceSynchronize();\n",
        "  cudaMemcpy(c,d_c,size,cudaMemcpyDeviceToHost);\n",
        "  auto end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "  printf(\"First 10 results:\\n\");\n",
        "  for (int i=0;i<10;i++){\n",
        "    printf(\"%d\\n\",c[i]);\n",
        "  }\n",
        "  cudaFree(d_a);\n",
        "  cudaFree(d_b);\n",
        "  cudaFree(d_c);\n",
        "\n",
        "  std::cout << \"CUDA Kernel Time:\"\n",
        "              << std::chrono::duration<double, std::milli>(end-start).count()\n",
        "              << \" ms\\n\";\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5T72ZTCHMyI",
        "outputId": "c1f2a21b-ae03-4bf0-f8ee-f922ce7ab999"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cuda_vector_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 cuda_vector_add.cu -o cuda_vector_add"
      ],
      "metadata": {
        "id": "ZXNZ6c8iI0Xg"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ./cuda_vector_add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHo7j7pbJrIH",
        "outputId": "7f0237ff-1c89-4e8b-ca66-b650e3d21f92"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 results:\n",
            "0\n",
            "3\n",
            "6\n",
            "9\n",
            "12\n",
            "15\n",
            "18\n",
            "21\n",
            "24\n",
            "27\n",
            "CUDA Kernel Time:0.201644 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile add.cu\n",
        "\n",
        "#include <thrust/host_vector.h>\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/transform.h>\n",
        "#include <iostream>\n",
        "#define N 1024\n",
        "\n",
        "int main(){\n",
        "\n",
        "  thrust::host_vector<float> h_a(N);\n",
        "  thrust::host_vector<float> h_b(N);\n",
        "  for (int i=0;i<N;i++){\n",
        "    h_a[i]=i;\n",
        "    h_b[i]=2*i;\n",
        "  }\n",
        "\n",
        "  auto start = std::chrono::high_resolution_clock::now();\n",
        "  thrust::device_vector<int>a=h_a;\n",
        "  thrust::device_vector<int>b=h_b;\n",
        "  thrust::device_vector<int>c(N);\n",
        "  thrust::transform(a.begin(),a.end(),b.begin(),c.begin(),thrust::plus<int>());\n",
        "  thrust::host_vector<int>h_c=c;\n",
        "  auto end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "  printf(\"First 10 results:\\n\");\n",
        "  for (int i=0;i<10;i++){\n",
        "    printf(\"%d\\n\",h_c[i]);\n",
        "  }\n",
        "\n",
        "  std::cout << \"Thrust Time:\"\n",
        "              << std::chrono::duration<double, std::milli>(end-start).count()\n",
        "              << \" ms\\n\";\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_nUyFRcHkre",
        "outputId": "573cc4e5-2efd-41df-f701-ec7df40360fd"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 add.cu -o add"
      ],
      "metadata": {
        "id": "i2MEIjPWI1Pa"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ./add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4kiqdmPJ4U5",
        "outputId": "006a15c3-c134-4a83-fbd4-d25f99df3dc4"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 results:\n",
            "0\n",
            "3\n",
            "6\n",
            "9\n",
            "12\n",
            "15\n",
            "18\n",
            "21\n",
            "24\n",
            "27\n",
            "Thrust Time:373.861 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rapids_vector_add.py\n",
        "import cudf\n",
        "import cupy as cp\n",
        "import time\n",
        "\n",
        "N = 5_000_000\n",
        "\n",
        "A = cp.ones(N, dtype=cp.float32)\n",
        "B = cp.full(N, 2.0, dtype=cp.float32)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "C = A + B\n",
        "\n",
        "cp.cuda.Stream.null.synchronize()\n",
        "end = time.time()\n",
        "\n",
        "print(\"RAPIDS (CuPy) Time:\", (end-start)*1000, \"ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDaroueiIrGf",
        "outputId": "2966bd60-bfc3-40cb-b47b-d0fa599e7603"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAPIDS (CuPy) Time: 88.28997611999512 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Write a CUDA C++ program using the Thrust library to compute the sum of all elements in a vector stored on the GPU. The vector is of size 10 and it should be initialized with values 1,…..10"
      ],
      "metadata": {
        "id": "0OR_1mvfKJF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile thrust_sum.cu\n",
        "\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/reduce.h>\n",
        "#include <iostream>\n",
        "\n",
        "int main()\n",
        "{\n",
        "    const int N = 10;\n",
        "    thrust::device_vector<int> d_vec(N);\n",
        "    for(int i=0;i<N;i++)\n",
        "    {\n",
        "        d_vec[i]=i+1;\n",
        "    }\n",
        "    int sum = thrust::reduce(d_vec.begin(),\n",
        "                             d_vec.end(),\n",
        "                             0,\n",
        "                             thrust::plus<int>());\n",
        "\n",
        "    std::cout << \"Sum of elements (1 to 10) = \" << sum << std::endl;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaKsVEbtJ_N2",
        "outputId": "c946d37f-daa7-4c65-b243-d4347e2e71ff"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing thrust_sum.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 thrust_sum.cu -o thrust_sum"
      ],
      "metadata": {
        "id": "W3KAneavKhW_"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ./thrust_sum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN2tYYE8Kmu7",
        "outputId": "f6150a8c-3e5e-421b-e768-e63b57c5e2ba"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of elements (1 to 10) = 55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Write a CUDA C++ program using Thrust to sort (ascending) a vector of integers on the GPU. Consider vector size 8 with following values: 7, 2, 9, 1, 5, 3, 8, 4. Print the vector before and afer sorting"
      ],
      "metadata": {
        "id": "jwNkoSmILXfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile thrust_sort.cu\n",
        "\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/host_vector.h>\n",
        "#include <thrust/sort.h>\n",
        "#include <iostream>\n",
        "\n",
        "int main()\n",
        "{\n",
        "    const int N = 8;\n",
        "    thrust::host_vector<int> h_vec(N);\n",
        "\n",
        "    int values[N] = {7, 2, 9, 1, 5, 3, 8, 4};\n",
        "\n",
        "    for(int i = 0; i < N; i++)\n",
        "        h_vec[i] = values[i];\n",
        "\n",
        "    std::cout << \"Before Sorting:\\n\";\n",
        "    for(int i = 0; i < N; i++)\n",
        "        std::cout << h_vec[i] << \" \";\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    thrust::device_vector<int> d_vec = h_vec;\n",
        "    thrust::sort(d_vec.begin(), d_vec.end());\n",
        "    h_vec = d_vec;\n",
        "\n",
        "    std::cout << \"After Sorting (Ascending):\\n\";\n",
        "    for(int i = 0; i < N; i++)\n",
        "        std::cout << h_vec[i] << \" \";\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t74MhP0GKqcA",
        "outputId": "781a4739-9b62-4a35-ae94-8752bb434163"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing thrust_sort.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 thrust_sort.cu -o thrust_sort"
      ],
      "metadata": {
        "id": "PYMWIGZKK9rd"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ./thrust_sort"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C968OvBLCrR",
        "outputId": "0f68935d-e2ac-483e-a90b-472c43239710"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Sorting:\n",
            "7 2 9 1 5 3 8 4 \n",
            "After Sorting (Ascending):\n",
            "1 2 3 4 5 7 8 9 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fXlgQVFDLGhp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}